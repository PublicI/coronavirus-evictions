---
title: "coronavirus-evictions"
author: "Joe Yerardi"
date: "5/14/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set working directory
setwd("C:/users/joeye/desktop/coronavirus-evictions")

# Set key file for the Google and Census Bureau API keys
key_file <- "key_file.txt"
```

```{r, echo = FALSE}
library("dplyr")
library("htmltools")
library("leaflet")
library("rgdal")
library("ggmap")
library("mapdeck")
library("purrr")
library("readr")
library("rgeos")
library("sf")
library("spData")
library("stringr")
library("tidyr")
library("tidycensus")
library("tidyverse")
library("tigris")
```

```{r import Westlaw case data}
# Import the list of cases
cases <- read_csv("data/cases.csv") %>% 
  select(case_title = "Case Title:",
         court = "Court:",
         case_number = "Case Number:",
         key_nature_of_suit = "Key Nature of Suit:",
         date_filed = "Date Filed:",
         judge = "Judge:",
         disposition = "Disposition:",
         docket_guid = guid)

# Import the list of participants
participants <- read_csv("data/participants.csv") %>% 
  select(participant = Name,
         type = "Type:",
         address = "Address:",
         docket_guid)

# Filter to just respondents and eliminate companies
respondents <- participants %>% 
  dplyr::filter(str_detect(type, regex("defendant|respondent|property|tenant", ignore_case = T)) &
                  str_detect(type, regex("counter", ignore_case = T), negate = T) &
                  str_detect(participant, regex(" corp| inc| llc", ignore_case = T), negate = T))

# Eliminate duplicate docket_guids so we're left with only one respondent per case
respondents_one_per_case <- respondents %>% 
  distinct(docket_guid, .keep_all = T)

# Join the respondents data frame to the cases data frame
evictions <- respondents_one_per_case %>% 
  inner_join(cases, by = "docket_guid")
```

```{r geocode the data}
# Read-in Google API key
google_key <- readLines(key_file)[1]

# Register key
register_google(key = google_key)

# Eliminate evictions with missing addresses
evictions_with_addresses <- evictions %>% 
  dplyr::filter(!is.na(address))

# Geocode the evictions
geocoding_results <- geocode(evictions_with_addresses$address, output = "more", source = "google")

# Rename columns
geocoding_results <- geocoding_results %>% 
  dplyr::rename("geocode_type" = "type",
                "geocode_address" = "address")

# Combine the geocoding results with the evictions
evictions_geocoded <- cbind(evictions_with_addresses, geocoding_results)

# Export the data
write_csv(evictions_geocoded, "data/exported/evictions_geocoded.csv")
```

```{r import Census race and income data}
# Read-in Census API key
census_key<- (readLines(key_file)[2])

# Create list of all US states to iterate through in the API calls
us <- unique(fips_codes$state)[1:51]

# Download median household income data
median_hh_inc <- map_df(us, function(x) {
  get_acs(geography = "tract", variables = "B19013_001", 
          state = x, key = census_key)
}) %>% 
  mutate(income_quartile = ntile(estimate, 4)) %>% 
  select(geoid = GEOID,
         geography = NAME,
         median_hh_income = estimate,
         income_quartile)

# Download race data
race <- map_df(us, function(x) {
  get_acs(geography = "tract", variables = c("B03002_001",
                                             "B03002_003"),
          state = x, key = census_key)
}) %>% pivot_wider(id_cols = c(GEOID, NAME),
              names_from = c(variable),
              values_from = estimate) %>% 
  mutate(non_white = B03002_001 - B03002_003,
         pct_white = round(B03002_003 / B03002_001 * 100, 1),
         pct_non_white = round(non_white / B03002_001 * 100, 1),
         above_avg_non_white = case_when(
           # 38.9% of the US population was non-white as per 2014-2018 ACS
           pct_non_white > 38.9 ~ T,
           pct_non_white <= 38.9 ~ F)) %>% 
  select(geoid = GEOID,
         geography = NAME,
         total_pop = B03002_001,
         white = B03002_003,
         non_white,
         pct_white,
         pct_non_white,
         above_avg_non_white)

# Join the census data
census <- race %>% 
  inner_join(median_hh_inc, by = "geoid") %>% 
  rename(geography = geography.x) %>% 
  select(-geography.y)
```

```{r geospatial analysis}
# Import the geocoded evictions data
evictions_geocoded <- read_csv("data/exported/evictions_geocoded.csv")

# Filter out rows with imprecise geocoding results
evictions_geocoded <- evictions_geocoded %>% 
  dplyr::filter(loctype == "rooftop" | loctype == "range_interpolated")
  
# Convert the data frame to an sf object
evictions_geocoded_sf <- st_as_sf(evictions_geocoded,
                                  crs = 4326,
                                  coords = c("lon", "lat"),
                                  remove = F)

# Set the path to the Census tracts geodatabase
gdb <- path.expand("C:/Users/joeye/Desktop/coronavirus-evictions/data/ACS_2018_5YR_TRACT.gdb")

# What are the layers contained in the geodatabase?
ogrListLayers(gdb)

# Extract the tracts layer
tracts <- readOGR(gdb, "ACS_2018_5YR_TRACT")

# Convert tracts from sp to sf object
tracts_sf <- st_as_sf(tracts)

# Reproject the tracts CRS to match that of the geocoded evictions
tracts_sf <- st_transform(tracts_sf,
                          crs = 4326)

# Join the evictions and census tracts layers, with each record being an eviction
evictions_tracts_joined <- st_join(evictions_geocoded_sf, tracts_sf)

# Join the evictions and census tracts layers, with each record being a tract
tracts_evictions_joined <- st_join(tracts_sf, evictions_geocoded_sf, left = F) %>% 
  group_by(GEOID) %>% 
  summarize(number_of_evictions = n())

# Export the data
st_write(evictions_tracts_joined, "data/exported/evictions_tracts_joined.geojson", driver = "GeoJSON")
st_write(tracts_evictions_joined, "data/exported/tracts_evictions_joined.geojson", driver = "GeoJSON")
```

```{r analyze the data}
# Import the data
evictions_tracts_joined <- read_sf("data/exported/evictions_tracts_joined.geojson")
tracts_evictions_joined <- read_sf("data/exported/tracts_evictions_joined.geojson")

# Join the Census data to the evictions data
evictions_tracts_census <- evictions_tracts_joined %>% 
  inner_join(census, by = c("GEOID" = "geoid")) %>% 
  select(1:16, 37:45, 36)

# Join the Census data to the tracts data
tracts_evictions_census <- tracts_evictions_joined %>% 
  inner_join(census, by = c("GEOID" = "geoid")) %>% 
  select(1:2, 4:12, 3)

# What proportion of evictions occur in census tract with above average proportions of non-white people?
evictions_tracts_census %>% 
  group_by(above_avg_non_white) %>% 
  summarize(num_evictions = n())

# What proportion of eviction cases were against tenants in majority-minority tracts?
evictions_tracts_census %>% 
  dplyr::filter(pct_non_white > 50.0) %>% 
  summarize(num_cases = n())

# And how many people live in such tracts?
census %>% 
  dplyr::filter(pct_non_white > 50.0) %>% 
  summarize(total_pop = sum(total_pop))

# And how many people live in the United States?
census %>% 
  summarize(total_pop = sum(total_pop))

# What proportion of evictions occur in tracts in each income quartile?
evictions_tracts_census %>% 
  group_by(income_quartile) %>% 
  summarize(num_evictions = n())

# What proportion of evictions occur in tracts with either an above average proportion of nonwhite people or that are in the lowest income quartile?
evictions_tracts_census %>% 
  dplyr::filter(above_avg_non_white == T | income_quartile == 1) %>% 
  summarize(num_evictions = n())

# What proportion of evictions occur in tracts with both an above average proportion of non-white people and that are in the lowest income quartile?
evictions_tracts_census %>% 
  dplyr::filter(above_avg_non_white == T & income_quartile == 1) %>% 
  summarize(num_evictions = n())

# And how many people live in such tracts?
census %>% 
  dplyr::filter(above_avg_non_white == T & income_quartile == 1) %>% 
  summarize(total_pop = sum(total_pop))

# And how many people live in the United States?
census %>% 
  summarize(total_pop = sum(total_pop))

# Which courts saw the highest number of evictions?
View(evictions_tracts_census %>% 
       group_by(court) %>% 
       summarize(num_evictions = n()) %>% 
       arrange(desc(num_evictions)))

# Which states saw the highest number of evictions?
View(evictions_tracts_census %>% 
       mutate(state = str_extract(geography, "\\b[^,]+$")) %>% 
       group_by(state) %>% 
       summarize(num_evictions = n()) %>% 
       arrange(desc(num_evictions)))

# Which tracts saw the highest number of evictions?
View(tracts_evictions_census %>% 
       arrange(desc(number_of_evictions)))

# How many eviction cases did Tzadik Management file in Florida?
View(participants %>% 
       distinct(docket_guid, .keep_all = T) %>% 
       dplyr::filter(str_detect(participant, regex("tzadik", ignore_case = T)) &
                       str_detect(type, regex("plaintiff", ignore_case = T)) &
                       str_detect(address, regex(", fl", ignore_case = T))))

# Is this the most of any landlord in Florida?
View(participants %>% 
       distinct(docket_guid, .keep_all = T) %>% 
       dplyr::filter(str_detect(type, regex("plaintiff", ignore_case = T)) &
                       str_detect(address, regex(", fl", ignore_case = T))) %>% 
       group_by(participant) %>% 
       summarize(num_evictions = n()) %>% 
       arrange(desc(num_evictions)))

# Who are the tenants that Tzadik is evicting?
tzadik_guids <- participants %>% 
       distinct(docket_guid, .keep_all = T) %>% 
       dplyr::filter(str_detect(participant, regex("tzadik", ignore_case = T)) &
                       str_detect(type, regex("plaintiff", ignore_case = T)) &
                       str_detect(address, regex(" fl", ignore_case = T))) %>% 
  select(docket_guid)

tzadik_evictions <- evictions_tracts_census %>% 
  inner_join(tzadik_guids, by = "docket_guid")

# What proportion of these Tzadik evictions occur in tracts with both an above average proportion of non-white people and that are in the lowest income quartile?
tzadik_evictions %>% 
  dplyr::filter(above_avg_non_white == T & income_quartile == 1) %>% 
  summarize(num_evictions = n())

# How many eviction cases did Embarcadero Club file in Georgia?
View(participants %>% 
       distinct(docket_guid, .keep_all = T) %>% 
       dplyr::filter(str_detect(participant, regex("embarcadero club", ignore_case = T)) &
                       str_detect(type, regex("plaintiff", ignore_case = T)) &
                       str_detect(address, regex(" ga", ignore_case = T))))

# Export the data
write_csv(evictions_tracts_census, "data/exported/evictions_tracts_census.csv")
write_csv(tracts_evictions_census, "data/exported/tracts_evictions_census.csv")
st_write(evictions_tracts_census, "data/exported/evictions_tracts_census.geojson", driver = "GeoJSON")
st_write(tracts_evictions_census, "data/exported/tracts_evictions_census.geojson", driver = "GeoJSON")
```

```{r map the data}
# Import the data
evictions_tracts_census <- read_sf("data/exported/evictions_tracts_census.geojson")
tracts_evictions_census <- read_sf("data/exported/tracts_evictions_census.geojson")

# Map the evictions
evictions_map <- evictions_tracts_census %>% 
  leaflet() %>% 
  addTiles() %>% 
  addCircles(lng = ~ lon, lat = ~ lat,
             weight = 5, radius = 30,
             popup = ~ paste(paste0("Participant: ", participant),
                             paste0("Court: ", court),
                             paste0("Percent Non-White: ", pct_non_white),
                             paste0("Above Average Non-White: ", above_avg_non_white),
                             paste0("Median Income: ", median_hh_income),
                             paste0("Income Quartile: ", income_quartile),
                             sep = "<br>"),
             label = ~ address)

evictions_map

# Map the tracts
pal <- colorNumeric("YlOrRd", domain = tracts_evictions_census$number_of_evictions)

tracts_map <- tracts_evictions_census %>% 
  leaflet() %>% 
  addTiles() %>% 
  addPolygons(fillColor = ~pal(tracts_evictions_census$number_of_evictions),
              fillOpacity = 1, 
              weight = 0.9, 
              smoothFactor = 0.2, 
              stroke=TRUE,
              color="white",
              popup = ~ paste(paste0("Number of Evictions: ", number_of_evictions),
                              paste0("Percent Non-White: ", pct_non_white),
                              paste0("Above Average Non-White: ", above_avg_non_white),
                              paste0("Median Income: ", median_hh_income),
                              paste0("Income Quartile: ", income_quartile),
                              sep = "<br>"),
              label = ~ geography) %>% 
  addLegend(pal = pal,
            values = tracts_evictions_census$number_of_evictions,
            position = "bottomright",
            title = "Number of Evictions")

tracts_map
```